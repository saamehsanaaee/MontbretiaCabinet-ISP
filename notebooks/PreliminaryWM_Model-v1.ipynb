{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20605108-a5aa-4396-a56f-5d9f234a730b",
   "metadata": {},
   "source": [
    "# Preliminary Working Memory Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378df91-d014-485f-9829-ab7df04d1c2e",
   "metadata": {},
   "source": [
    "This is the model that our team created during the 2024 Neuromatch Summer School.\n",
    "\n",
    "\n",
    "(Insert a shit ton of README-style explanation for the preliminary model OR put the info in the main README file for both models.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac9f1ec-6739-4ec9-89a5-d06a6c50a680",
   "metadata": {},
   "source": [
    "## Setup and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb92641-c3cf-47f4-bb62-180c6033e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nilearn --quiet\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f7dbe-ac71-47b1-828d-2f3223a6741d",
   "metadata": {},
   "source": [
    "## Figure settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ae7e3a-28f9-42f5-9913-513f8cd07ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be replaced by the xkcd style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee36a4c-d83a-49e5-bf9c-4d08cedb511d",
   "metadata": {},
   "source": [
    "## Parameters and Data Download\n",
    "The data used for the preliminary model was shared by Neuromatch in the [Project Booklets](https://compneuro.neuromatch.io/projects/fMRI/README.html#:~:text=5%2D23%2C%202021-,HCP%20task%20datasets,-%23) and most of our data preparation is similar to what they have shared in the ```load_hcp_task_with_behaviour.ipynb``` in the [HCP 2021 + behavior](https://compneuro.neuromatch.io/projects/fMRI/README.html#:~:text=View-,HCP%202021%20%2B%20behavior,-HCP%202021) section.\n",
    "\n",
    "Our target experiments (```TargetExperiments``` variable below) are Working Memory, Emotion, and Language tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "164f224f-8915-46aa-bc0a-6d3631a0282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SUBJECTS = 100\n",
    "N_PARCELS = 360 # Data aggregated into ROIs from Glasser parcellation\n",
    "TR = 0.72  # Time resolution, in seconds\n",
    "HEMIS = [\"Right\", \"Left\"]\n",
    "RUNS   = ['LR','RL']\n",
    "N_RUNS = 2\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    'MOTOR'      : {'cond':['lf','rf','lh','rh','t','cue']},\n",
    "    'WM'         : {'cond':['0bk_body','0bk_faces','0bk_places','0bk_tools','2bk_body','2bk_faces','2bk_places','2bk_tools']},\n",
    "    'EMOTION'    : {'cond':['fear','neut']},\n",
    "    'GAMBLING'   : {'cond':['loss','win']},\n",
    "    'LANGUAGE'   : {'cond':['math','story']},\n",
    "    'RELATIONAL' : {'cond':['match','relation']},\n",
    "    'SOCIAL'     : {'cond':['ment','rnd']}\n",
    "}\n",
    "\n",
    "TargetExperiments = ['WM', 'EMOTTION', 'LANGUAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d4d6525-7ec2-429f-a058-fd097522a128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9568\\3387722393.py:20: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tfile.extractall('.')\n"
     ]
    }
   ],
   "source": [
    "fname = \"hcp_task.tgz\"\n",
    "url = \"https://osf.io/2y3fw/download\"\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "  try:\n",
    "    r = requests.get(url)\n",
    "  except requests.ConnectionError:\n",
    "    print(\"Download FAILED: Connection Error!\")\n",
    "  else:\n",
    "    if r.status_code != requests.codes.ok:\n",
    "      print(\"Download FAILED!\")\n",
    "    else:\n",
    "      with open(fname, \"wb\") as fid:\n",
    "        fid.write(r.content)\n",
    "\n",
    "\n",
    "HCP_DIR = \"./hcp_task\"\n",
    "\n",
    "with tarfile.open(fname) as tfile:\n",
    "  tfile.extractall('.')\n",
    "\n",
    "SubjectIDs = np.loadtxt(os.path.join(HCP_DIR, 'subjects_list.txt'), dtype='str')\n",
    "SubjectIDs = list(SubjectIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb3ba4-3b6f-4d7a-87f3-a14635bc8909",
   "metadata": {},
   "source": [
    "### ```regions.npy``` file and parcels\n",
    "(Insert doc about what the regions file is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a310d1ea-68d2-4c00-b376-ea19552835f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = np.load(f\"{HCP_DIR}/regions.npy\").T\n",
    "\n",
    "region_info = dict(\n",
    "    name=regions[0].tolist(),\n",
    "    network=regions[1],\n",
    "    hemi=['Right']*int(N_PARCELS/2) + ['Left']*int(N_PARCELS/2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c41ca0-5f1a-45ef-b6f4-9055151ad397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "THIS SECTION OF CODE WILL BE REPLACED BY CODE THAT DIRECTLY EXTRACTS\n",
    "THE NUMBERS AND CONSTUCTS THE DICTIONARY FROM THE regions.npy FILE.\n",
    "\"\"\"\n",
    "\n",
    "ventral_attention_parcels    = [121, 134]\n",
    "\n",
    "orbital_affective_parcels    = [111, 165, 289, 291, 345]\n",
    "\n",
    "dorsal_attention_parcels     = [26, 139, 140, 206, 207, 320]\n",
    "\n",
    "limbic_parcels               = [109, 111, 165, 289, 291, 345]\n",
    "\n",
    "auditory_parcels             = [23, 102, 103, 123, 172, 173, \n",
    "                                174, 282, 286, 287, 288, 303, 352, 353, 354]\n",
    "\n",
    "default_mode_parcels         = [11, 24, 25, 27, \n",
    "                                73, 74, 78, 80, 122, 124, 127, 128, 138, 171, \n",
    "                                191, 205, 254, 258, 302, 304, 308, 318, 351]\n",
    "\n",
    "language_parcels             = [10, 45, 49, 94, \n",
    "                                95, 115, 126, 135, 136, 142, 145, 225, 229, \n",
    "                                274, 275, 295, 296, 306, 315, 316, 322, 325]\n",
    "\n",
    "frontoparietal_parcels       = [13, 14, \n",
    "                                28, 62, 72, 76, 79, 81, 82, 84, 96, 97, 110, \n",
    "                                132, 143, 144, 148, 169, 170, 208, 242, 252,\n",
    "                                256, 259, 260, 262, 264, 276, 277, 290, 298]\n",
    "\n",
    "somatomotor_parcels          = [7, 8, 35, 38, 39, 40, 41, 46, \n",
    "                                50, 51, 52, 53, 54, 55, 99, 100, 101, 167, \n",
    "                                187, 188, 215, 218, 219, 220, 221, 226, 230, \n",
    "                                231, 232, 233, 234, 235, 279, 280, 281, 347]\n",
    "\n",
    "cingulo_opercular_parcels    = [9, 36, 37, 42, 43, 44, 56, 57, 58, 59, 98, \n",
    "                                104, 105, 107, 112, 113, 114, 116, 178, 179, \n",
    "                                189, 190, 204, 216, 217, 222, 223, 224, 236, \n",
    "                                237, 238, 239, 257, 261, 263, 265, 275, 277, \n",
    "                                285, 292, 293, 346, 348, 357, 358, 359]\n",
    "\n",
    "visual_parcels               = [0, 1, 2, 3, 4, 5, 6,\n",
    "                                12, 15, 16, 17, 18, 19, 20, 21, 22, 47, 48,\n",
    "                                137, 141, 151, 152, 153, 155, 156, 157, 158, \n",
    "                                159, 162, 186, 192, 195, 196, 197, 198, 199, \n",
    "                                200, 201, 202, 227, 228, 317, 321, 331, 332, \n",
    "                                333, 335, 336, 337, 338, 339, 342]\n",
    "\n",
    "posterior_multimodal_parcels = [29, 30, 31, 32, 33, 34, 60, 61, 63, 64, 65, \n",
    "                                66, 67, 68, 69, 70, 71, 75, 86, 87, 88, 89, \n",
    "                                117, 118, 119, 130, 131, 133, 154, 160, 161, \n",
    "                                163, 164, 175, 176, 177, 180, 181, 182, 183, \n",
    "                                184, 185, 192, 193, 194, 195, 196, 197, 198, \n",
    "                                199, 200, 201, 202, 214, 215, 216, 217, 218, \n",
    "                                219, 220, 221, 230, 231, 232, 233, 234, 235, \n",
    "                                246, 247, 248, 249, 250, 251, 252, 253, 255, \n",
    "                                266, 267, 269, 270, 271, 272, 273, 276, 277, \n",
    "                                278, 279, 280, 281, 283, 284, 297, 299, 300, \n",
    "                                301, 305, 307, 309, 310, 311, 312, 313, 314, \n",
    "                                319, 323, 324, 326, 327, 328, 329, 330, 341, \n",
    "                                344, 349, 350]\n",
    "\n",
    "# Dictionary of subnetworks with no. of parcels and the list of corresponding parcels.\n",
    "subnetworks = {\n",
    "    f\"visual_nw_{len(visual_parcels)}\"                             : visual_parcels             ,\n",
    "    f\"limbic_nw_{len(limbic_parcels)}\"                             : limbic_parcels             ,\n",
    "    f\"auditory_nw_{len(auditory_parcels)}\"                         : auditory_parcels           ,\n",
    "    f\"language_nw_{len(language_parcels)}\"                         : language_parcels           ,\n",
    "    f\"somatomotor_nw_{len(somatomotor_parcels)}\"                   : somatomotor_parcels        ,\n",
    "    f\"default_mode_nw_{len(default_mode_parcels)}\"                 : default_mode_parcels       ,\n",
    "    f\"frontoparietal_nw_{len(frontoparietal_parcels)}\"             : frontoparietal_parcels     ,\n",
    "    f\"dorsal_attention_nw_{len(dorsal_attention_parcels)}\"         : dorsal_attention_parcels   ,\n",
    "    f\"cingulo_opercular_nw_{len(cingulo_opercular_parcels)}\"       : cingulo_opercular_parcels  ,\n",
    "    f\"orbital_affective_nw_{len(orbital_affective_parcels)}\"       : orbital_affective_parcels  ,\n",
    "    f\"ventral_attention_nw_{len(ventral_attention_parcels)}\"       : ventral_attention_parcels  ,\n",
    "    f\"posterior_multimodal_nw_{len(posterior_multimodal_parcels)}\" : posterior_multimodal_parcels\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55ec67",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Here, we define funtions that we will be using for creating the dataframe and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c095c-35cd-4955-b92f-87d39e08e467",
   "metadata": {},
   "source": [
    "### Functions for the data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8230ac96-8706-4e8b-af90-3433e8abb437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_timeseries(subject, experiment, run, remove_mean=True):\n",
    "    \"\"\"Load timeseries data for a single subject and single run.\n",
    "\n",
    "    Arguments:\n",
    "        subject (str):      subject ID to load\n",
    "        experiment (str):   Name of experiment\n",
    "        run (int):          (0 or 1)\n",
    "        remove_mean (bool): If True, subtract the parcel-wise mean\n",
    "                            (typically the mean BOLD signal is not of interest)\n",
    "\n",
    "    Returns\n",
    "        ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
    "    \n",
    "    \"\"\"\n",
    "    bold_run  = RUNS[run]\n",
    "    bold_path = f\"{HCP_DIR}/subjects/{subject}/{experiment}/tfMRI_{experiment}_{bold_run}\"\n",
    "    bold_file = \"data.npy\"\n",
    "    ts_path   = f\"{bold_path}/{bold_file}\"\n",
    "    \n",
    "    if not os.path.exists(ts_path):\n",
    "        raise FileNotFoundError(f\"Timeseries file not found: {ts_path}\")\n",
    "    ts = np.load(ts_path)\n",
    "    \n",
    "    if remove_mean:\n",
    "        ts = ts - ts.mean(axis=1, keepdims=True)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b38cc12d-3364-4a7a-8a7d-3d6f1a15e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evs(subject, experiment, run):\n",
    "    \"\"\"Load EVs (explanatory variables) data for one task experiment.\n",
    "\n",
    "    Arguments:\n",
    "        subject (str): subject ID to load\n",
    "        experiment (str): Name of experiment\n",
    "        run (int): 0 or 1\n",
    "\n",
    "    Returns:\n",
    "        evs (list of lists): A list of frames associated with each condition\n",
    "    \n",
    "    \"\"\"\n",
    "    frames_list = []\n",
    "    task_key = f\"tfMRI_{experiment}_{RUNS[run]}\"\n",
    "    for cond in EXPERIMENTS[experiment][\"cond\"]:\n",
    "        ev_file  = f\"{HCP_DIR}/subjects/{subject}/{experiment}/{task_key}/EVs/{cond}.txt\"\n",
    "        ev_array = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
    "        ev       = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
    "        \n",
    "        # Determine when trial starts, rounded down\n",
    "        start = np.floor(ev[\"onset\"] / TR).astype(int)\n",
    "        # Use trial duration to determine how many frames to include for trial\n",
    "        duration = np.ceil(ev[\"duration\"] / TR).astype(int)\n",
    "        # Take the range of frames that correspond to this specific trial\n",
    "        frames = [s + np.arange(0, d) for s, d in zip(start, duration)]\n",
    "        frames_list.append(frames)\n",
    "\n",
    "    return frames_list\n",
    "\n",
    "\n",
    "def load_evs_as_dict(subject, experiment, run):\n",
    "    \"\"\"Load EVs (explanatory variables) data for one task experiment.\n",
    "\n",
    "    Arguments:\n",
    "        subject (str): subject ID to load\n",
    "        experiment (str): Name of experiment\n",
    "        run (int): 0 or 1\n",
    "\n",
    "    Returns:\n",
    "        evs (dict): A dictionary of the data associated with each condition\n",
    "    \n",
    "    \"\"\"\n",
    "    evs = {}\n",
    "    task_key = f\"tfMRI_{experiment}_{RUNS[run]}\"\n",
    "\n",
    "    for cond  in EXPERIMENTS[experiment][\"cond\"]:\n",
    "        ev_file = f\"{HCP_DIR}/subjects/{subject}/{experiment}/{task_key}/EVs/{cond}.txt\"\n",
    "        if not os.path.exists(ev_file):\n",
    "            raise FileNotFoundError(f\"EV file not found: {ev_file}\")\n",
    "        ev_array  = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
    "        evs[cond] = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
    "\n",
    "    return evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa5ca005-ffac-4953-8663-d4f6ce37d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(subject, experiment):\n",
    "    \"\"\"\n",
    "    Creates a dataframe that contains the parcel-based \n",
    "    BOLD signals from a subject for each condition.\n",
    "\n",
    "    Arguments:\n",
    "        subject (str): subject ID to load\n",
    "        experiment (str): Name of experiment\n",
    "\n",
    "    Returns:\n",
    "        A dataframe of parcel-based BOLD data\n",
    "        for one subject and one experiment\n",
    "        \n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for run in range(2): # Run can be 0 (LR) or 1 (RL)\n",
    "        try:\n",
    "            ts  = load_single_timeseries(subject, experiment, run)\n",
    "            evs = load_evs_as_dict(subject, experiment, run)\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        n_parcels, n_timepoints = ts.shape\n",
    "\n",
    "        for condition, ev_data in evs.items():\n",
    "            onset_times = ev_data[\"onset\"]\n",
    "            durations   = ev_data[\"duration\"]\n",
    "            amplitudes  = ev_data[\"amplitude\"]\n",
    "\n",
    "            for onset, duration, amplitude in zip(onset_times, durations, amplitudes):\n",
    "                start_frame = int(onset / TR)\n",
    "                end_frame   = start_frame + int(duration / TR)\n",
    "\n",
    "                for time_point in range(start_frame, end_frame):\n",
    "                    if time_point < n_timepoints: # Ensure it is within bounds\n",
    "                        row = {\n",
    "                            \"sunject\"      : subject   ,\n",
    "                            \"experiment\"   : experiment,\n",
    "                            \"run\"          : RUNS[run] ,\n",
    "                            \"condition\"    : condition ,\n",
    "                            \"timepoint\"    : time_point,\n",
    "                            \"EV_onset\"     : onset     ,\n",
    "                            \"EV_duration\"  : duration  ,\n",
    "                            \"EV_amplitude\" : amplitude\n",
    "                        }\n",
    "                        # Add BOLD signal data for all parcels\n",
    "                        row.update({f\"parcel_{i}\": ts[i, time_point] for i in range(n_parcels)})\n",
    "                        all_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e370f1-6737-46a2-a98f-03f85ca1041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stats(subject, experiment):\n",
    "    \"\"\"Aggregates all data for a subject into\n",
    "    a dictionary that can be used along with\n",
    "    \"gather_all_subjects_stats()\" to create\n",
    "    the final dataframe.\n",
    "\n",
    "    Arguments:\n",
    "        subjects    (list of str): list of SubjectIDs\n",
    "        experiments (list of str): list of TargetExperiments\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of all the data points\n",
    "        for a subject's specific experiment.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    stats_dict = {\"subject\": subject}\n",
    "    task_path  = f\"{HCP_DIR}/subjects/{subject}/{experiment}/tfMRI_{experiment}_LR/EVs\"\n",
    "\n",
    "    if os.path.exists(task_path):\n",
    "        for filename in os.listdir(task_path):\n",
    "            if filename == \"Stats.txt\":\n",
    "                filepath = os.path.join(task_path, filename)\n",
    "                with open(filepath, \"r\") as file:\n",
    "                    lines = file.readlines()\n",
    "                    for line in lines:\n",
    "                        match = re.match(r\"([\\w\\s-]+): ([\\d.]+)\", line.strip())\n",
    "                        if match:\n",
    "                            key, value = match.groups()\n",
    "                            stats_dict[f\"{experiment}_{key.strip().replace(\" \", \"_\")}\"] = float(value)\n",
    "\n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57d0cbb6-2d1f-4870-84a3-99ba61b0e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_all_subjects_stats(subjects, experiments):\n",
    "    \"\"\"Creates a dataframe containing all data from\n",
    "    all subjects which stores the parcel-based BOLD signals.\n",
    "\n",
    "    Arguments:\n",
    "        subjects    (list of str): list of SubjectIDs\n",
    "        experiments (list of str): list of TargetExperiments\n",
    "\n",
    "    Returns:\n",
    "        A dataframe of parcel-based BOLD data\n",
    "        for all subjects and all experiments\n",
    "    \n",
    "    \"\"\"\n",
    "    all_stats = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        subject_stats = {\"subject\": subject}\n",
    "        for experiment in experiments:\n",
    "            stats = extract_stats(subject, experiment)\n",
    "            subject_stats.update(stats)\n",
    "\n",
    "            # Get the dimensions of DataFrame for this subject and experiment\n",
    "            try:\n",
    "                df = create_dataframe(subject, experiment)\n",
    "                subject_stats[f\"{experiment}_num_rows\"] = df.shape[0]\n",
    "                subject_stats[f\"{experiment}_num_cols\"] = df.shape[1]\n",
    "            except FileNotFoundError:\n",
    "                subject_stats[f\"{experiment}_num_rows\"] = None\n",
    "                subject_stats[f\"{experiment}_num_cols\"] = None\n",
    "        \n",
    "        all_stats.append(subject_stats)\n",
    "\n",
    "    stats_df = pd.DataFrame(all_stats)\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "143c7fbd-57ae-4461-adc3-4070bc38a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stats_to_csv(df, filename):\n",
    "    \"\"\"Saves the input dataframe as a csv in working directory.\n",
    "\n",
    "    Arguments:\n",
    "        df (dataframe)\n",
    "        filename (str)\n",
    "    \"\"\"\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0472b49-8de0-494d-bd50-65e740ca1244",
   "metadata": {},
   "source": [
    "### Functions related to EDA, correlation, and subnetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89bac95-7b3b-454a-a710-2a5b2a30e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# THIS FUNCTION MIGHT NOT BE NEEDED.\n",
    "#\n",
    "\n",
    "def compute_binary_covariance_matrix(cov_matrix, threshold = 0.5):\n",
    "    \"\"\"Calculates the binary covariance matrix.\n",
    "\n",
    "    Arguments:\n",
    "        cov_matrix (): ???\n",
    "        threshold  (): ??? (Default is 0.5)\n",
    "\n",
    "    Returns:\n",
    "        ??? (Seems to be a 0 or 1 output based on the threshold)\n",
    "        \n",
    "    \"\"\"\n",
    "    binary_covariance_matrix = (cov_matrix.abs() > threshold).astype (int)\n",
    "    return binary_covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e6439-979a-40b2-a9ff-4dc44c16dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# THIS FUNCTION MIGHT NOT BE NEEDED.\n",
    "# ALSO, WHERE DOES \n",
    "#\n",
    "\n",
    "def plot_correlation_heatmap(parcels, parcel_name):\n",
    "    \"\"\"Plots the correlation matrix between parcels.\n",
    "\n",
    "    Arguments:\n",
    "        parcels    (list): List of parcel numbers \"parcel_name\" network\n",
    "        parcel_name (str): Name of network\n",
    "\n",
    "    Returns:\n",
    "        The correlation heatmap of parcels from selected network\n",
    "\n",
    "    Example usage:\n",
    "        plot_correlation_heatmap(language_parcels, \"Language Network\")\n",
    "        \n",
    "        Where \"language_parcels\" is a list\n",
    "        of parcels in the \"Language Network\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # Extract selected parcels\n",
    "    # \"+1\" to adjust for the \"condition\" column being the first\n",
    "    selected_data = data.iloc[:, [0]+[i+1 for i in parcels]] \n",
    "\n",
    "    # Transpose to put tasks in rows and parcels in columns\n",
    "    transposed_data = selected_data.iloc[:, 1:].transpose()\n",
    "\n",
    "    # Fix labels and create correlation matrix\n",
    "    conditions = data[\"condition\"]\n",
    "    correlation_matrix_tasks         = transposed_data.corr()\n",
    "    correlation_matrix_tasks.index   = conditions\n",
    "    correlation_matrix_tasks.columns = conditions\n",
    "\n",
    "    plt.figure(figsize = (10, 8))\n",
    "    sns.heatmap(correlation_matrix_tasks, cmap = \"coolwarm\", \n",
    "                center = 0, annot = True, fmt = \".2f\")\n",
    "    plt.title(f\"Correlation Matrix Heatmap of Tasks based on BOLD Signals ({parcel_name})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418ae5f-c741-426a-8b4a-a0a6d6a39a7e",
   "metadata": {},
   "source": [
    "### Functions for the matrix construction and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41180c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c880417c-d5ea-4a42-a8df-0467c4c7b865",
   "metadata": {},
   "source": [
    "## Creating dataframes\n",
    "Here, we create dataframes that contain the data relative to subjects and ROIs (parcels).\n",
    "\n",
    "In the preliminary model, this datapoints are the average BOLD signals for each parcel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28f03c37-e243-4715-af73-6a480bac5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using functions that we have already defined ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6395b8b-6c67-48e1-914a-f862492e9b89",
   "metadata": {},
   "source": [
    "## Filters and Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1292c52-c44c-4d98-812c-804393131637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These codes could be removed.\n",
    "\n",
    "# For the improved model, we'll use the resting baseline -> Always-active parcels and meaningful activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97ec1a-173b-4144-af21-78f11e9d080c",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060a96b-e5b0-4663-8cc7-f0dfbc9d3808",
   "metadata": {},
   "source": [
    "### Parcels and Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0b25d-927c-4997-8536-13e190199d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "THIS SECTION SHOULD BE BASED OFF OF THE \"GENERAL EDA\" SECTION OF THE ORIGINAL CODE.\n",
    "\"\"\"\n",
    "\n",
    "# Plot heatmaps for relevant subnetworks\n",
    "plot_correlation_heatmap( visual_parcels         , \"Visual Network\"        )\n",
    "plot_correlation_heatmap( language_parcels       , \"Language Network\"      )\n",
    "plot_correlation_heatmap( default_mode_parcels   , \"Default Mode Network\"  )\n",
    "plot_correlation_heatmap( frontoparietal_parcels , \"Frontoparietal Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e040077-f6b7-4e7c-84ce-6198154996fd",
   "metadata": {},
   "source": [
    "### Subnetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7853b-aed8-45e2-a2a9-1329a8c8eab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80f9a440-480c-4bf9-8c77-d32b7feae306",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55186708-3b40-4675-a558-14a5295ab525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76302446-fcd1-47ee-b904-5083cc80b118",
   "metadata": {},
   "source": [
    "## Matrix Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f9996-4aa4-4c3a-8456-5fa0a5a70d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ac578-eb76-4973-9ae1-8c5ef4b81f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248a459-8d3b-4bad-8585-3ef22c177c8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The MLP Model (2 output version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce14799-0215-44ea-bce6-b682d3df2e2b",
   "metadata": {},
   "source": [
    "### Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2d066-cb63-4c02-8826-331bfa6564bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4c0222a-b694-4ac1-859c-829754071dde",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457ce4b-87c0-4172-9963-0aa0a20d4419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b5311c0-a883-40b1-845c-b604e070609f",
   "metadata": {},
   "source": [
    "### Taining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2f4d3-2902-474b-90b5-2f5dfb9c87f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54704349-7de5-43ea-9ca6-eb3ddb27cc2b",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b63f4-ef35-42a2-a2b4-217289849da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28ba9363-280f-4bd2-9ed2-25c2b4037e21",
   "metadata": {},
   "source": [
    "### Evaluation and Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005d3ff-f685-478a-8a73-fa11cd6e9809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05423654-aa08-497a-aa04-0666a9e66f09",
   "metadata": {},
   "source": [
    "### Using the Model to predict Emotion and Language tasks\n",
    "After our Working Memory Model was trained, we gave it the Emotion and Language task data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa27bcc-2bab-4dff-a23b-9a56326b1d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508b6d0d-0dd6-44c2-8dda-2d4a63511ad9",
   "metadata": {},
   "source": [
    "### Comparison of Model Predictions\n",
    "Here, we used 3D plots to compare how our model performed in terms of predicting the different conditions of Emotion and Language tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af02b817-0778-4565-b5fa-533321345e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abdf2a53-9b51-4231-a6aa-c4637c49cebb",
   "metadata": {},
   "source": [
    "## The MLP Model (8 output version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
